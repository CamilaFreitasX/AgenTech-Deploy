# No in√≠cio do arquivo, substitua:
import streamlit as st
import pandas as pd
import zipfile
import os
import tempfile
from io import StringIO

# Tente este import alternativo:
try:
    from langchain_experimental.agents import create_csv_agent
except ImportError:
    from langchain.agents import create_csv_agent

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents.agent_types import AgentType
from utils_google import NotaFiscalValidator, extract_zip_file
import warnings
from dotenv import load_dotenv

load_dotenv()

import streamlit as st
import warnings
warnings.filterwarnings("ignore")

class CSVAnalysisAgent:
    def __init__(self, google_api_key=None):
        """Inicializa o agente de an√°lise CSV com Google Gemini"""
        self.google_api_key = google_api_key
        self.agents = {}
        self.dataframes = {}
        self.file_info = {}
        
    def create_llm(self):
        """Cria uma inst√¢ncia do modelo Google Gemini"""
        if not self.google_api_key:
            raise ValueError("Google API Key √© necess√°ria para usar o agente")
        
        try:
            llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-flash",
                temperature=0.3,  # Aumentar para mais flexibilidade
                convert_system_message_to_human=True
            )
            return llm
        except Exception as e:
            st.error(f"Erro ao criar modelo Gemini: {str(e)}")
            return None
    
    def load_csv_data(self, file_path, file_type):
        """Carrega dados CSV e cria agente espec√≠fico"""
        try:
            # L√™ o arquivo CSV
            df = pd.read_csv(file_path, encoding='utf-8')
            
            # Armazena o dataframe
            self.dataframes[file_type] = df
            self.file_info[file_type] = {
                'path': file_path,
                'shape': df.shape,
                'columns': df.columns.tolist()
            }
            
            # Cria o LLM
            llm = self.create_llm()
            if llm is None:
                return False
            
            # Cria agente espec√≠fico para este CSV
            agent = create_csv_agent(
                llm,
                file_path,
                verbose=True,
                agent_type=AgentType.OPENAI_FUNCTIONS,
                allow_dangerous_code=True,
                handle_parsing_errors=True
            )
            
            self.agents[file_type] = agent
            return True
            
        except Exception as e:
            st.error(f"Erro ao carregar arquivo {file_type}: {str(e)}")
            return False
    
    def create_general_agent(self):
        """Cria um agente geral que pode acessar todos os dataframes"""
        try:
            if not self.dataframes:
                print("Erro: Nenhum dataframe carregado")
                return None
            
            llm = self.create_llm()
            if llm is None:
                print("Erro: N√£o foi poss√≠vel criar LLM")
                return None
            
            # Coleta TODOS os caminhos de arquivos v√°lidos usando file_info
            valid_paths = []
            for file_type, df in self.dataframes.items():
                # CORRE√á√ÉO: usar self.file_info ao inv√©s de getattr
                file_path = self.file_info.get(file_type, {}).get('path')
                if file_path and os.path.exists(file_path):
                    valid_paths.append(file_path)
                    print(f"Arquivo v√°lido: {file_path}")
                else:
                    print(f"Arquivo n√£o encontrado para {file_type}: {file_path}")
            
            if not valid_paths:
                print("Erro: Nenhum arquivo CSV v√°lido encontrado")
                return None
            
            print(f"Criando agente com {len(valid_paths)} arquivos: {valid_paths}")
            
            # SEMPRE tenta criar com TODOS os arquivos primeiro
            try:
                # Linha ~120
                general_agent = create_csv_agent(
                    llm,
                    valid_paths,
                    verbose=True,
                    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                    allow_dangerous_code=True,
                    handle_parsing_errors=True,
                    max_iterations=20,  # Aumentar de 10 para 20
                    early_stopping_method="generate",
                    agent_executor_kwargs={
                        "handle_parsing_errors": True,
                        "max_execution_time": 300  # Aumentar de 120 para 300 segundos
                    }
                )
                
                print(f"‚úÖ Agente criado com sucesso para {len(valid_paths)} arquivos")
                return general_agent
                
            except Exception as e:
                print(f"‚ùå Erro ao criar agente com m√∫ltiplos arquivos: {str(e)}")
                
                # Se falhar com m√∫ltiplos arquivos, tenta abordagem pandas
                if len(valid_paths) > 1:
                    try:
                        print("üîÑ Tentando abordagem pandas com todos os dataframes...")
                        
                        from langchain.agents import create_pandas_dataframe_agent
                        
                        # Converte todos os dataframes em uma lista
                        all_dfs = list(self.dataframes.values())
                        df_names = list(self.dataframes.keys())
                        
                        general_agent = create_pandas_dataframe_agent(
                            llm,
                            all_dfs,
                            verbose=True,
                            agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                            allow_dangerous_code=True,
                            handle_parsing_errors=True,
                            prefix=f"Voc√™ tem acesso aos seguintes dataframes: {', '.join(df_names)}. Use df_0 para {df_names[0]}, df_1 para {df_names[1]}, etc."
                        )
                        
                        print(f"‚úÖ Agente pandas criado com {len(all_dfs)} dataframes")
                        return general_agent
                        
                    except Exception as e2:
                        print(f"‚ùå Erro na abordagem pandas: {str(e2)}")
                    
                # √öltimo recurso: apenas um arquivo
                try:
                    print(f"‚ö†Ô∏è Fallback: criando agente apenas para {valid_paths[0]}")
                    general_agent = create_csv_agent(
                        llm,
                        valid_paths[0],
                        verbose=True,
                        agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                        allow_dangerous_code=True,
                        handle_parsing_errors=True
                    )
                    print(f"‚ö†Ô∏è Agente criado apenas para: {valid_paths[0]}")
                    return general_agent
                except Exception as e3:
                    print(f"‚ùå Erro no fallback: {str(e3)}")
                    return None
                
        except Exception as e:
            print(f"‚ùå Erro geral: {str(e)}")
            st.error(f"Erro ao criar agente geral: {str(e)}")
            return None
    
    def query(self, question, agent_type="geral"):
        """Executa uma consulta usando o agente especificado"""
        try:
            # Debug apenas no console, n√£o na resposta
            # print(f"\n=== DEBUG: Iniciando consulta ===")
            # print(f"Pergunta: {question}")
            # print(f"Dados dispon√≠veis: {list(self.dataframes.keys())}")
            
            if agent_type == "geral":
                agent = self.create_general_agent()
                if agent is None:
                    return "Erro: N√£o foi poss√≠vel criar o agente geral."
            else:
                agent = self.agents.get(agent_type)
                if agent is None:
                    return f"Erro: Agente para {agent_type} n√£o encontrado."
            
            # Instru√ß√£o MUITO espec√≠fica para o agente - SEMPRE EM PORTUGU√äS
            enhanced_question = f"""
            Voc√™ √© um especialista em an√°lise de dados financeiros de notas fiscais.
            
            DADOS DISPON√çVEIS: {', '.join(self.dataframes.keys())}
            PERGUNTA: {question}
            
            METODOLOGIA OBRIGAT√ìRIA (baseada no ChatGPT):
            1. Carregue o arquivo de cabe√ßalho das notas fiscais
            2. Converta a coluna 'VALOR NOTA FISCAL' para float
            3. Agrupe por 'RAZ√ÉO SOCIAL EMITENTE' (nome do fornecedor)
            4. Some os valores para obter total por fornecedor
            5. Ordene de forma descendente
            6. Identifique o fornecedor com maior valor
            
            C√ìDIGO PANDAS OBRIGAT√ìRIO:
            ```python
            import pandas as pd
            
            # 1. Verificar estrutura dos dados
            print("Colunas dispon√≠veis:")
            print(df.columns.tolist())
            print("\nPrimeiras linhas:")
            print(df.head())
            
            # 2. Converter coluna de valor para num√©rico
            df['VALOR NOTA FISCAL'] = pd.to_numeric(df['VALOR NOTA FISCAL'], errors='coerce')
            
            # 3. Agrupar por fornecedor e somar valores
            resultado = df.groupby('RAZ√ÉO SOCIAL EMITENTE')['VALOR NOTA FISCAL'].sum()
            
            # 4. Ordenar de forma descendente
            resultado_ordenado = resultado.sort_values(ascending=False)
            
            # 5. Obter o maior
            maior_fornecedor = resultado_ordenado.index[0]
            maior_valor = resultado_ordenado.iloc[0]
            
            print(f"\nFornecedor com maior montante: {maior_fornecedor}")
            print(f"Valor total: R$ {maior_valor:,.2f}")
            
            # 6. Mostrar top 5 para verifica√ß√£o
            print("\nTop 5 fornecedores:")
            for i, (fornecedor, valor) in enumerate(resultado_ordenado.head().items()):
                print(f"{i+1}. {fornecedor}: R$ {valor:,.2f}")
            ```
            
            INSTRU√á√ïES CR√çTICAS:
            - Use EXATAMENTE os nomes das colunas: 'VALOR NOTA FISCAL' e 'RAZ√ÉO SOCIAL EMITENTE'
            - SEMPRE converta valores para num√©rico antes de somar
            - SEMPRE mostre o c√≥digo executado
            - SEMPRE responda em portugu√™s brasileiro
            - Use v√≠rgula como separador decimal (R$ 1.234,56)
            - NUNCA invente dados - use apenas o que est√° nos arquivos
            - Se der erro, verifique os nomes das colunas com df.columns
            """
            
            INSTRU√á√ïES CR√çTICAS:
            1. SEMPRE use pandas para an√°lise: df.groupby(), df.sum(), df.max()
            2. Para encontrar maior valor: use df.groupby('fornecedor').sum().idxmax()
            3. SEMPRE verifique os dados com df.head(), df.info(), df.describe()
            4. Para valores monet√°rios: use format(valor, ',.2f').replace(',', 'X').replace('.', ',').replace('X', '.')
            5. SEMPRE responda em portugu√™s brasileiro
            6. Use dados do arquivo 'cabecalho' para totais por fornecedor
            7. NUNCA invente dados - apenas use o que est√° nos arquivos
            8. Mostre o c√≥digo pandas executado
            9. Verifique m√∫ltiplas vezes os c√°lculos
            10. Se houver d√∫vida, reanalise os dados
            
            EXEMPLO DE C√ìDIGO OBRIGAT√ìRIO:
            ```python
            # Verificar dados
            print(df_cabecalho.columns)
            print(df_cabecalho.head())
            
            # Agrupar por fornecedor e somar valores
            resultado = df_cabecalho.groupby('nome_fornecedor')['valor_total'].sum()
            maior_fornecedor = resultado.idxmax()
            maior_valor = resultado.max()
            
            print(f"Fornecedor: {maior_fornecedor}")
            print(f"Valor: R$ {maior_valor:,.2f}")
            ```
            
            # print("Executando consulta...")  # Debug apenas no console
            response = agent.invoke({"input": enhanced_question})
            # print(f"Tipo da resposta: {type(response)}")  # Debug apenas no console
            
            if isinstance(response, dict):
                result = response.get("output", response.get("result", ""))
            else:
                result = str(response)
            
            # print(f"Resultado: {result[:200]}...")  # Debug apenas no console
            
            # P√≥s-processamento para garantir portugu√™s e limpar debug
            if result and str(result).strip():
                result_str = str(result).strip()
                
                # Remove linhas de debug que possam ter vazado
                lines = result_str.split('\n')
                clean_lines = []
                for line in lines:
                    # Remove linhas que cont√™m informa√ß√µes de debug
                    if not any(debug_term in line.lower() for debug_term in 
                             ['debug:', 'tipo da resposta', 'executando', '===', 'print(']):
                        clean_lines.append(line)
                
                result_str = '\n'.join(clean_lines).strip()
                
                # Se a resposta ainda estiver em ingl√™s, for√ßa tradu√ß√£o b√°sica
                if any(word in result_str.lower() for word in ['the supplier', 'with the highest', 'total received', 'final answer']):
                    result_str = result_str.replace('The supplier with the highest total received value is:', 'O fornecedor com o maior valor total recebido √©:')
                    result_str = result_str.replace('Final Answer:', 'Resposta Final:')
                    result_str = result_str.replace('with a total of', 'com um total de')
                    
                return result_str
            else:
                return "O agente n√£o conseguiu processar a consulta. Verifique se os dados foram carregados corretamente."
                
        except Exception as e:
            # print(f"Erro geral: {str(e)}")  # Debug apenas no console
            return f"Erro ao processar consulta: {str(e)}"
    
    def get_data_summary(self):
        """Retorna um resumo dos dados carregados"""
        summary = {}
        for file_type, df in self.dataframes.items():
            summary[file_type] = {
                'linhas': len(df),
                'colunas': len(df.columns),
                'colunas_lista': df.columns.tolist(),
                'tipos': df.dtypes.to_dict(),
                'primeiras_linhas': df.head().to_dict('records')
            }
        return summary

def main():
    st.set_page_config(
        page_title="Agente de An√°lise de Notas Fiscais - Google Gemini",
        page_icon="üìä",
        layout="wide"
    )
    
    st.title("ü§ñ Agente Inteligente para An√°lise de Notas Fiscais")
    st.markdown("### Powered by Google Gemini API & LangChain")
    st.markdown("---")
    
    # Carrega a API key do arquivo .env
    google_api_key = os.getenv("GOOGLE_API_KEY")
    
    if not google_api_key:
        st.error("‚ö†Ô∏è GOOGLE_API_KEY n√£o encontrada no arquivo .env")
        return
    
    # Inicializa o agente
    if 'csv_agent' not in st.session_state:
        st.session_state.csv_agent = CSVAnalysisAgent(google_api_key)
    
    # Upload de arquivos
    st.header("üìÅ Upload de Arquivos")
    uploaded_file = st.file_uploader(
        "Fa√ßa upload do arquivo ZIP contendo os CSVs de notas fiscais",
        type=['zip'],
        help="Upload do arquivo ZIP contendo os arquivos CSV das notas fiscais"
    )
    
    if uploaded_file is not None:
        with st.spinner("Processando arquivos..."):
            # Extrai o arquivo ZIP
            temp_dir = extract_zip_file(uploaded_file)
            
            if temp_dir:
                st.success("‚úÖ Arquivo ZIP extra√≠do com sucesso!")
                
                # Processa os arquivos CSV
                validator = NotaFiscalValidator()
                csv_files = [f for f in os.listdir(temp_dir) if f.endswith('.csv')]
                
                loaded_files = []
                for csv_file in csv_files:
                    file_path = os.path.join(temp_dir, csv_file)
                    file_type = validator.identify_file_type(file_path)
                    
                    if file_type != "unknown":
                        success = st.session_state.csv_agent.load_csv_data(file_path, file_type)
                        if success:
                            loaded_files.append(f"{csv_file} ({file_type})")
                
                if loaded_files:
                    st.success(f"‚úÖ Arquivos carregados: {', '.join(loaded_files)}")
                    
                    # Mostra resumo dos dados
                    with st.expander("üìä Resumo dos Dados Carregados"):
                        summary = st.session_state.csv_agent.get_data_summary()
                        for file_type, info in summary.items():
                            st.subheader(f"üìÑ {file_type.title()}")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("Linhas", info['linhas'])
                                st.metric("Colunas", info['colunas'])
                            with col2:
                                st.write("**Colunas:**")
                                st.write(", ".join(info['colunas_lista']))
                            
                            # Mostra primeiras linhas
                            if st.checkbox(f"Ver primeiras linhas - {file_type}", key=f"show_{file_type}"):
                                df_display = pd.DataFrame(info['primeiras_linhas'])
                                st.dataframe(df_display, use_container_width=True)
    
    # Interface de consultas
    if hasattr(st.session_state, 'csv_agent') and st.session_state.csv_agent.dataframes:
        st.header("üîç Fa√ßa suas perguntas")
        
        # Exemplos de perguntas
        with st.expander("üí° Exemplos de Perguntas"):
            st.markdown("""
            - Qual √© o fornecedor que teve maior montante recebido?
            - Qual item teve maior volume entregue (em quantidade)?
            - Quantas notas fiscais foram emitidas no total?
            - Qual √© a soma total de todos os valores das notas fiscais?
            - Quais s√£o os 5 fornecedores com maior valor total?
            - Qual √© a m√©dia de valor por item?
            - Quantos itens diferentes foram comprados?
            - Qual √© o produto mais caro?
            - Em que per√≠odo foram emitidas as notas fiscais?
            - Qual √© a distribui√ß√£o de valores por fornecedor?
            """)
        
        # Campo de pergunta
        user_question = st.text_area(
            "Digite sua pergunta sobre os dados:",
            placeholder="Ex: Qual √© o fornecedor que teve maior montante recebido?",
            height=100
        )
        
        if st.button("üöÄ Executar Consulta", type="primary"):
            if user_question.strip():
                with st.spinner("Processando consulta..."):
                    response = st.session_state.csv_agent.query(user_question)
                    
                    # Exibe apenas a resposta limpa
                    st.markdown("### üìã Resposta:")
                    
                    # Cria um expander para detalhes t√©cnicos (opcional)
                    with st.expander("üîß Detalhes T√©cnicos (clique para ver)", expanded=False):
                        st.write("Tipo da resposta:", type(response))
                        st.write("Conte√∫do bruto:", response)
                    
                    # Exibe a resposta principal de forma limpa
                    if response and str(response).strip():
                        # Remove poss√≠veis prefixos de debug
                        clean_response = str(response).strip()
                        
                        # Remove linhas que come√ßam com "Tipo da resposta" ou similar
                        lines = clean_response.split('\n')
                        clean_lines = []
                        for line in lines:
                            if not any(debug_prefix in line.lower() for debug_prefix in 
                                     ['tipo da resposta', 'conte√∫do da resposta', 'debug:', '===']):
                                clean_lines.append(line)
                        
                        final_response = '\n'.join(clean_lines).strip()
                        
                        # Exibe a resposta final
                        st.markdown(final_response)
                    else:
                        st.error("N√£o foi poss√≠vel obter uma resposta v√°lida.")
            else:
                st.warning("‚ö†Ô∏è Por favor, digite uma pergunta.")
    
    # Informa√ß√µes adicionais
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìö Sobre")
    st.sidebar.markdown("""
    Esta aplica√ß√£o utiliza:
    - **Google Gemini API** para processamento de linguagem natural
    - **LangChain** para cria√ß√£o de agentes inteligentes
    - **Streamlit** para interface web
    - **Pandas** para manipula√ß√£o de dados
    """)
    
    st.sidebar.markdown("### üîó Links √öteis")
    st.sidebar.markdown("""
    - [Google AI Studio](https://ai.google.dev/)
    - [LangChain Documentation](https://python.langchain.com/)
    - [Streamlit Documentation](https://docs.streamlit.io/)
    """)

if __name__ == "__main__":
    main()
    
    # üö® Problema Confirmado: Aplica√ß√£o Ainda D√° Respostas Incorretas
    
    # Vejo que mesmo ap√≥s as tentativas de melhorias, a aplica√ß√£o ainda est√° fornecendo dados incorretos:
    
    # - **Resposta da Aplica√ß√£o:** EDITORA FTD S.A. com R$ 6.712,16
    # - **Resposta Correta:** CHEMYUNION LTDA com R$ 1.292.418,75
    
    # Isso indica que as mudan√ßas ainda n√£o foram aplicadas ou n√£o s√£o suficientes.
    
    # üîß Solu√ß√£o Definitiva: Aplicar Mudan√ßas Mais Robustas
    
    # Vamos implementar melhorias mais espec√≠ficas no c√≥digo:
    
    # ### **1. Verificar se as Mudan√ßas Foram Aplicadas**
    
    # Primeiro, confirme se o arquivo local tem essas configura√ß√µes:
    
    # Linha ~43 - Temperature
    temperature=0.5,  # AUMENTAR AINDA MAIS para 0.5
    
    # Linha ~126 - Max Iterations  
    max_iterations=30,  # AUMENTAR para 30
    
    # Linha ~130 - Max Execution Time
    "max_execution_time": 600  # AUMENTAR para 600 segundos